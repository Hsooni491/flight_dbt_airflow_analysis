# Flight ELT with Airflow & dbt

**Flight-dbt-airflow-analysis** is a production-grade ELT pipeline demonstrating modern data engineering best practices for aviation analytics. Apache Airflow orchestrates the workflow, AviationStack supplies live flight data, PostgreSQL stores the landing zone, and dbt transforms raw records into business-ready data marts.

---

## âœ¨ Highlights

- **Automated Orchestration** â€“ Airflow DAG (`airflow/dags/flight_elt_dag.py`) orchestrates the complete extract â†’ load â†’ transform workflow
- **Resilient Ingestion** â€“ `extract_flights_data` normalizes AviationStack API responses and enforces schemas before loading
- **Warehouse-Ready Loading** â€“ Pandas + SQLAlchemy efficiently push curated rows into the `raw_flights` table
- **Modular Transformations** â€“ dbt models (`flight_dbt/`) deliver staging layers plus airline, airport, and status fact tables
- **Test-First Mindset** â€“ Pytest coverage (`airflow/dags/extract/tests`) validates custom operators and mocks Airflow XCom behavior
- **Structured Logging** â€“ Custom logging integrated across extract & load steps for enhanced observability and debugging

---

## ğŸ“Š Architecture

```
AviationStack API 
    â†“
Airflow Extract Task (with logging)
    â†“
PostgreSQL raw_flights table
    â†“
dbt Models (staging + marts)
    â†“
Curated Data Marts
```

**ELT Pipeline Flow:**
1. **Extract** â€“ `extract_flights_data` calls the AviationStack API, limits payload size, logs request/response metadata, and shapes JSON data
2. **Load** â€“ `load_flights_data` retrieves XCom records, logs insert operations, and appends data to PostgreSQL via SQLAlchemy
3. **Transform** â€“ BashOperator triggers `dbt run` in `flight_dbt/`, building staging models and fact marts on top of `raw_flights`

---

## ğŸªµ Logging

The project includes an enhanced logging layer for comprehensive traceability throughout the ELT pipeline.

### What's Logged?

- API call events with request start/end timestamps
- Number of records extracted per run
- Schema validation results and data quality checks
- Data load operations (rows inserted, target table, connection status)
- Error handling with detailed exception messages and stack traces

### Where Logs Appear

- **Airflow Task Logs** â€“ Located in `airflow/logs/...` with full task execution history
- **Python Application Logs** â€“ Using standard `logging` module within:
  - `extract_flights_data`
  - `load_flights_data`

### Why It Matters

Enhanced logging provides:
- **Faster Debugging** â€“ Quickly identify API failures or database connection issues
- **ETL Throughput Visibility** â€“ Track record counts and processing times
- **Production-Grade Observability** â€“ Monitor pipeline health and data quality in real-time
- **Audit Trail** â€“ Complete record of all extraction and loading operations

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Orchestration** | Apache Airflow 2.x |
| **Database** | PostgreSQL 14+ with SQLAlchemy |
| **Transformation** | dbt Core (Postgres adapter) |
| **Language** | Python 3.10+ |
| **Data Processing** | pandas, requests |
| **Testing** | pytest |
| **Observability** | Python logging module |

---

## ğŸ“ Repository Structure

```
flight-dbt-airflow-analysis/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ flight_elt_dag.py              # Main DAG definition
â”‚   â”‚   â””â”€â”€ extract/
â”‚   â”‚       â”œâ”€â”€ extract_flights.py         # Extract/load helpers with logging
â”‚   â”‚       â””â”€â”€ tests/
â”‚   â”‚           â””â”€â”€ test_elt_functions.py  # Unit tests
â”‚   â””â”€â”€ logs/                              # Airflow task logs
â”œâ”€â”€ flight_dbt/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/                       # Staging layer models
â”‚   â”‚   â””â”€â”€ marts/                         # Business logic marts
â”‚   â””â”€â”€ dbt_project.yml                    # dbt configuration
â”œâ”€â”€ raw_flights_sample.json                # Sample API response
â””â”€â”€ README.md
```

---

## ğŸš€ Setup

### 1. Clone the Repository

```bash
git clone https://github.com/Hsooni491/flight-dbt-airflow-analysis.git
cd flight-dbt-airflow-analysis
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install apache-airflow pandas sqlalchemy psycopg2-binary requests dbt-postgres pytest
```

### 4. Configure Credentials

- Set `ACCESS_KEY` in `extract_flights.py` with your AviationStack API key
- Update `database_url` in `flight_elt_dag.py` or configure via Airflow connections

### 5. Prepare PostgreSQL

- Ensure database and schema exist
- The loader automatically creates the `raw_flights` table if missing

---

## â–¶ï¸ Running the Pipeline

### Initialize Airflow

```bash
export AIRFLOW_HOME=$(pwd)/airflow
airflow db init
airflow users create \
  --username admin \
  --password admin \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com
```

### Start Airflow Services

```bash
# Terminal 1: Start webserver
airflow webserver --port 8080

# Terminal 2: Start scheduler
airflow scheduler
```

### Execute the DAG

1. Navigate to `http://localhost:8080`
2. Enable the `elt_tasks` DAG in the UI
3. Trigger manually or wait for scheduled run
4. Inspect logs to view extract/load/transform steps with detailed logging

---

## ğŸ”„ dbt Workflow

Run dbt transformations independently:

```bash
cd flight_dbt
dbt run    # Execute all models
dbt test   # Run data quality tests
```

---

## ğŸ§ª Testing

Run the test suite:

```bash
pytest airflow/dags/extract/tests/test_elt_functions.py
```

The test suite includes:
- Unit tests for extraction logic
- XCom behavior mocking
- Schema validation tests
- Error handling verification

---

## ğŸ“§ Contact

For questions, collaboration opportunities, or bug reports:
- **GitHub Issues**: [Open an issue](https://github.com/Hsooni491/flight-dbt-airflow-analysis/issues)
- **LinkedIn**: [Alhussain Baalawi](https://www.linkedin.com/in/alhussain-baalawi)

---

**Built with â¤ï¸ for modern data engineering**